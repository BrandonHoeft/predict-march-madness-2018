Develop Initial Model
================
Brandon Hoeft
March 3, 2018

-   [Overview](#overview)
-   [Data](#data)
-   [Data Wrangling](#data-wrangling)
    -   [Feature Creation](#feature-creation)
-   [Feature Exploration](#feature-exploration)

Overview
--------

A lot of the work in this initial analysis will be structured around wrangling data provided by Google and NCAA for the [Google Cloud & NCAA® ML Competition 2018 Men's](https://www.kaggle.com/c/mens-machine-learning-competition-2018), building initial features, and training/testing a minimum viable model for predicting outcomes of NCAA basketball games.

Research into initial features for a predictive model have been informed by advanced NBA statistics derived from traditional box score data, which was made available by the competition sponsors.

Goals of the competition are two-fold:

**1**: You should submit predicted probabilities for every possible matchup in the past 4 NCAA® tournaments (2014-2017).

**2**: You should submit predicted probabilities for every possible matchup before the 2018 tournament begins.

Data
----

I'm primarily working with the dataset called *RegularSeasonDetailedResults.csv*, which has detailed aggregate box score stats for every game for each team played. See the [data dictionary](https://www.kaggle.com/c/mens-machine-learning-competition-2018/data) for more details.

    Observations: 76,636
    Variables: 38
    $ Season     <int> 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 200...
    $ DayNum     <int> 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13,...
    $ WTeamID    <int> 1104, 1272, 1266, 1296, 1400, 1458, 1161, 1186, 119...
    $ WTeam_name <chr> "Alabama", "Memphis", "Marquette", "N Illinois", "T...
    $ WTeam_conf <chr> "sec", "cusa", "cusa", "mac", "big_twelve", "big_te...
    $ WScore     <int> 68, 70, 73, 56, 77, 81, 80, 75, 71, 84, 106, 74, 66...
    $ LTeamID    <int> 1328, 1393, 1437, 1457, 1208, 1186, 1236, 1457, 115...
    $ LTeam_name <chr> "Oklahoma", "Syracuse", "Villanova", "Winthrop", "G...
    $ LTeam_conf <chr> "big_twelve", "big_east", "big_east", "big_south", ...
    $ LScore     <int> 62, 63, 61, 50, 71, 55, 62, 61, 66, 56, 50, 73, 65,...
    $ WLoc       <chr> "N", "N", "N", "N", "N", "H", "H", "N", "N", "H", "...
    $ NumOT      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...
    $ WFGM       <int> 27, 26, 24, 18, 30, 26, 23, 28, 28, 32, 41, 29, 26,...
    $ WFGA       <int> 58, 62, 58, 38, 61, 57, 55, 62, 58, 67, 69, 51, 66,...
    $ WFGM3      <int> 3, 8, 8, 3, 6, 6, 2, 4, 5, 5, 15, 7, 5, 10, 11, 10,...
    $ WFGA3      <int> 14, 20, 18, 9, 14, 12, 8, 14, 11, 17, 25, 13, 19, 2...
    $ WFTM       <int> 11, 10, 17, 17, 11, 23, 32, 15, 10, 15, 9, 9, 9, 16...
    $ WFTA       <int> 18, 19, 29, 31, 13, 27, 39, 21, 18, 19, 13, 11, 13,...
    $ WOR        <int> 14, 15, 17, 6, 17, 12, 13, 13, 9, 14, 15, 6, 21, 8,...
    $ WDR        <int> 24, 28, 26, 19, 22, 24, 18, 35, 22, 22, 29, 21, 23,...
    $ WAst       <int> 13, 16, 15, 11, 12, 12, 14, 19, 9, 11, 21, 18, 15, ...
    $ WTO        <int> 23, 13, 10, 12, 14, 9, 17, 19, 17, 6, 11, 15, 17, 1...
    $ WStl       <int> 7, 4, 5, 14, 4, 9, 11, 7, 9, 12, 10, 7, 12, 14, 18,...
    $ WBlk       <int> 1, 4, 2, 2, 4, 3, 1, 2, 2, 0, 6, 1, 3, 19, 5, 6, 3,...
    $ WPF        <int> 22, 18, 25, 18, 20, 18, 25, 21, 23, 13, 16, 5, 17, ...
    $ LFGM       <int> 22, 24, 22, 18, 24, 20, 19, 20, 24, 23, 17, 29, 24,...
    $ LFGA       <int> 53, 67, 73, 49, 62, 46, 41, 59, 52, 52, 52, 63, 56,...
    $ LFGM3      <int> 2, 6, 3, 6, 6, 3, 4, 4, 6, 3, 4, 10, 6, 8, 4, 7, 2,...
    $ LFGA3      <int> 10, 24, 26, 22, 16, 11, 15, 17, 18, 14, 11, 22, 19,...
    $ LFTM       <int> 16, 9, 14, 8, 17, 12, 20, 17, 12, 7, 12, 5, 11, 4, ...
    $ LFTA       <int> 22, 20, 23, 15, 27, 17, 28, 23, 27, 12, 17, 5, 17, ...
    $ LOR        <int> 10, 20, 31, 17, 21, 6, 9, 8, 13, 9, 8, 13, 14, 14, ...
    $ LDR        <int> 22, 25, 22, 20, 15, 22, 21, 25, 26, 23, 15, 16, 21,...
    $ LAst       <int> 8, 7, 9, 9, 12, 8, 11, 10, 13, 10, 8, 15, 17, 12, 1...
    $ LTO        <int> 18, 12, 12, 19, 10, 19, 30, 15, 25, 18, 17, 12, 18,...
    $ LStl       <int> 9, 8, 2, 4, 7, 4, 10, 14, 8, 1, 7, 6, 8, 10, 7, 5, ...
    $ LBlk       <int> 2, 6, 5, 3, 1, 3, 4, 8, 2, 3, 3, 2, 4, 0, 7, 1, 3, ...
    $ LPF        <int> 20, 16, 23, 23, 14, 25, 28, 18, 18, 18, 15, 12, 13,...

Data Wrangling
--------------

For the game data to be potentially useful in predicting the outcomes of games, the inputs cannot have [data leakage](https://www.kaggle.com/wiki/Leakage).

-   **simplest approach**: create features that represent regular season summary aggregates as predictors for each team in the NCAA tournament. Use all outcomes of NCAA tournament games from 2003-2013 as target.

-   **better approach**: create features that are cumulative aggregates throughought the course of the regular season. As such, training observations can be basically every single game outcome from the regular season, with the features in each row representing the rolling, aggregate summary stats of the team as of the day of the season prior to the exam. This enables much more training records to build a model off of. To test the model, we'll still use the aggregate features as of the last day of the regular season, as inputs to predict tournament performance.

### Feature Creation

Some initial predictors I am considering developing, which will be lagging aggregates of team and opponent performance include:

-   

Feature Exploration
-------------------

WORK IN PROGRESS. Not sure if I'll publish these findings.
