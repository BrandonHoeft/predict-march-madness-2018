---
title: "Develop Initial Model"
author: "Brandon Hoeft"
date: "March 3, 2018"
output:
  github_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = "",
                      fig.height = 6, fig.width = 6)
options(scipen=999) # turn of scientific notation.
library(ggplot2)
```

## Overview

A lot of the work in this initial analysis will be structured around wrangling data provided by Google and NCAA for the [Google Cloud & NCAA® ML Competition 2018 Men's](https://www.kaggle.com/c/mens-machine-learning-competition-2018), building initial features, and training/testing a minimum viable model for predicting outcomes of NCAA basketball games. 

Research into initial features for a predictive model have been informed by advanced NBA statistics derived from traditional box score data, which was made available by the competition sponsors. 

Goals of the competition are two-fold:

**1**: You should submit predicted probabilities for every possible matchup in the past 4 NCAA® tournaments (2014-2017).

**2**: You should submit predicted probabilities for every possible matchup before the 2018 tournament begins.

## Data

I'm primarily working with the dataset called *RegularSeasonDetailedResults.csv*, which has detailed aggregate box score stats for every game for each team played. See the [data dictionary](https://www.kaggle.com/c/mens-machine-learning-competition-2018/data) for more details. 

``` {r data_import, echo = FALSE}
library(aws.s3)
library(readr)
library(dplyr)
# specify personal account keys as environment variables so I can read my s3 object(s) from AWS. 
# DO NOT SAVE KEY in code or render in output!!!! Could compromise AWS account. 
# Note to self my key and secret last gen from October 2017. 
#Sys.setenv("AWS_ACCESS_KEY_ID" = "",
#           "AWS_SECRET_ACCESS_KEY" = "")

RegularSeasonDetailedResults <- s3read_using(FUN = read_csv, 
                      object = "RegularSeasonDetailedResults.csv",
                      bucket = "ncaabasketball")

team_conference <- s3read_using(FUN = read_csv, 
                      object = "TeamConferences.csv",
                      bucket = "ncaabasketball")

team_name <- s3read_using(FUN = read_csv, 
                      object = "Teams.csv",
                      bucket = "ncaabasketball")

# detailed box score results data for all NCAA Tournament games 2003 - 2017
NCAATourneyDetailedResults <- s3read_using(FUN = read_csv, 
                      object = "NCAATourneyDetailedResults.csv",
                      bucket = "ncaabasketball")

# detailed box score results data for all regular season NCAA D1 games 2003 - 2017
regular_season_details <- RegularSeasonDetailedResults %>%
    # conference of winning team.
    left_join(team_conference, by = c("WTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of winning team.
    left_join(team_name, by = c("WTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(WTeam_conf = ConfAbbrev,
           WTeam_name = TeamName) %>%
    # conference of losing team.
    left_join(team_conference, by = c("LTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of losing team.
    left_join(team_name, by = c("LTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(LTeam_conf = ConfAbbrev,
           LTeam_name = TeamName) %>%
    select(Season, DayNum, WTeamID, WTeam_name, WTeam_conf, WScore,
           LTeamID, LTeam_name, LTeam_conf, LScore, everything())

glimpse(regular_season_details)
```
 
## Data Wrangling

For the game data to be potentially useful in predicting the outcomes of games, the inputs cannot have [data leakage](https://www.kaggle.com/wiki/Leakage). 

*  **simplest approach**: create features that represent regular season summary aggregates as predictors for each team in the NCAA tournament. Use all outcomes of NCAA tournament games from 2003-2013 as target. 

*  **better approach**: create features that are cumulative aggregates throughought the course of the regular season. As such, training observations can be basically every single game outcome from the regular season, with the features in each row representing the rolling, aggregate summary stats of the team as of the day of the season prior to the exam. This enables much more training records to build a model off of. To test the model, we'll still use the aggregate features as of the last day of the regular season, as inputs to predict tournament performance. 

### Feature Creation 

Some initial predictors I am considering developing, which will be lagging aggregates of team and opponent performance will primarily focus on rate type metrics, as opposed to counting statistics. The former remove the bias of context such as playing style/tempo, which contribute towards noise in counting stats (ex. total points, total 3p made, etc). Some examples include

*  Points per Possession (PPP):  this is an offensive efficiency metric. 

*  Defensive Points per Possession (dPPP): this is a  defensive efficiency metric.

*  Dean Oliver's [Four Factors](https://www.basketball-reference.com/about/factors.html): concepts from a noteworthy basketball statistician's factors for basketball success. I will consider accounting for shooting efficiency, turnovers, rebounding, and free throw performance. 

*  Matchup Differentials: A really cool insight or hypothesis I learned from good 'ole internet research is that algorithms that treat bracketology as a ranking problem assume that the transitive property applies to head to head match ups. 

*  

``` {r feature_creating, echo = TRUE}

```

## Feature Exploration

WORK IN PROGRESS. Not sure if I'll publish these findings. 
