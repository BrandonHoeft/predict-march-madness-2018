---
title: "Develop Initial Model"
author: "Brandon Hoeft"
date: "March 3, 2018"
output:
  github_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = "",
                      fig.height = 6, fig.width = 6)
options(scipen=999) # turn of scientific notation.
library(pryr) # mem_used() and object_size() functions to manage/understand memory usage.

```

## Overview

The work in this analysis will be structured around wrangling data provided by Google and NCAA for the [Google Cloud & NCAA® ML Competition 2018 Men's](https://www.kaggle.com/c/mens-machine-learning-competition-2018), building initial features, and training/testing a minimum viable model for predicting outcomes of NCAA basketball games. 

Research into initial features for a predictive model have been informed by advanced NBA statistics derived from traditional box score data, which was made available by the competition sponsors. 

Goals of the competition are two-fold:

**1**: You should submit predicted probabilities for every possible matchup in the past 4 NCAA® tournaments (2014-2017).

**2**: You should submit predicted probabilities for every possible matchup before the 2018 tournament begins.

## Data

I'm primarily working with the dataset called *RegularSeasonDetailedResults.csv*, which has detailed aggregate box score stats for every game for each team played. See the [data dictionary](https://www.kaggle.com/c/mens-machine-learning-competition-2018/data) for more details. The data is structured in such a way that each row represents a single game between two teams with columns representing box score statistics for each the winning and the losing team.

``` {r data_import, echo = FALSE}
library(aws.s3)
library(readr)
library(dplyr)
# specify personal account keys as environment variables so I can read my s3 object(s) from AWS. 
# DO NOT SAVE KEY in code or render in output!!!! Could compromise AWS account. 
# Note to self my key and secret last gen from October 2017. 
#Sys.setenv("AWS_ACCESS_KEY_ID" = "",
#           "AWS_SECRET_ACCESS_KEY" = "")

RegularSeasonDetailedResults <- s3read_using(FUN = read_csv, 
                      object = "RegularSeasonDetailedResults.csv",
                      bucket = "ncaabasketball")

team_conference <- s3read_using(FUN = read_csv, 
                      object = "TeamConferences.csv",
                      bucket = "ncaabasketball")

team_name <- s3read_using(FUN = read_csv, 
                      object = "Teams.csv",
                      bucket = "ncaabasketball")

# Massey Rankings website.
#rankings <- s3read_using(FUN = read_csv, 
#                      object = "MasseyOrdinals.csv",
#                      bucket = "ncaabasketball")

# https://fivethirtyeight.blogs.nytimes.com/2011/03/14/how-we-made-our-n-c-a-a-picks/
#rankings <- rankings %>%
#    filter(SystemName %in% c("POM", # Pomeroy
#                             "SAG", # Sagarin (USA Today)
#                             "RPI")) # Rating % Index. Accounts for Strength of Schedule. 

# detailed box score results data for all NCAA Tournament games 2003 - 2017
NCAATourneyDetailedResults <- s3read_using(FUN = read_csv, 
                      object = "NCAATourneyDetailedResults.csv",
                      bucket = "ncaabasketball")

# detailed box score results data for all regular season NCAA D1 games 2003 - 2017
reg_season_details <- RegularSeasonDetailedResults %>%
    # conference of winning team.
    left_join(team_conference, by = c("WTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of winning team.
    left_join(team_name, by = c("WTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(WTeam_conf = ConfAbbrev,
           WTeam_name = TeamName) %>%
    # conference of losing team.
    left_join(team_conference, by = c("LTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of losing team.
    left_join(team_name, by = c("LTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(LTeam_conf = ConfAbbrev,
           LTeam_name = TeamName) %>%
    select(Season, DayNum, WTeamID, WTeam_name, WTeam_conf, WScore,
           LTeamID, LTeam_name, LTeam_conf, LScore, everything())

glimpse(reg_season_details)
```

Due to the data wrangling that will follow, I created a unique game identifier of each specific game matchup by concatenating the Season, DayNum, WTeamID, LTeamID. From my inspection, omitting the *day* from the game ID string creates duplicates as teams may play each other multiple times in a season where the Winning and Losing team were the same. 

``` {r game_id, echo = TRUE}
reg_season_details <- reg_season_details %>%
    mutate(game_id = paste(Season, DayNum, WTeamID, LTeamID, sep = "_")) %>%
    select(game_id, everything())
    
# check unique. Should have value of 1. 
reg_season_details %>%
    group_by(game_id) %>%
    summarize(frequency = n()) %>%
    arrange(desc(frequency)) %>% slice(1:5)
```

## Data Wrangling Approach

For the game data to be potentially useful in predicting the outcomes of games, the inputs cannot have [data leakage](https://www.kaggle.com/wiki/Leakage). 

*  **simplest approach**: create features that represent regular season summary aggregates as predictors for each team that exist in the NCAA tournament from 2003-2017. Use all games of NCAA tournament games from 2003-2013 to train a model. 

*  **better approach**: create features that are cumulative 1-day lag summary statistics measured over the course of each team's regular season. As such, training observations can be any single game outcome from the regular season. The features in each row could represent in-season summary stats leading up to the game day in question. This enables much more training records to build a model off of. To test the model, we'll still use the aggregate features as of the last day of the regular season, as inputs to predict that season's NCAA tournament performance. 

### Per game Rate/Efficiency Measurements 

Some of the first things I want to create from the data in *RegularSeasonDetailedResults.csv* is to capture rate and efficiency based statistics (as opposed to frequency or count stats) about the the winning team and the losing team of each game. Frequency or count based stats are known to be filled with bias that add too much noise *For example, a team's very high points per game might be a function of a fast paced playing style, and not because they're efficient or good shooters.* These initial measures are not going to be predictors in a model, but are the first step towards creating predictors/features. 

Some examples and other sources of inspiration include:

*  Points per Possession (PPP):  this is an offensive efficiency metric adjusted to per 100 possessions. 
*  Defensive Points per Possession (dPPP): this is a  defensive efficiency metric to per 100 possessions.

*  Dean Oliver's [Four Factors](https://www.basketball-reference.com/about/factors.html): concepts from a noteworthy basketball statistician's factors for basketball success. Areas to consider include shooting, rebounding, turnovers, free throws. 

* Efficiency type metrics as published by [Ken Pomeroy](https://kenpom.com/blog/ratings-glossary/)

```{r}

# get opponent stats so we can calculate defensive effective FG% (FGM, FGM3, FGA), defensive TO%, defensive ORB%, defensive FT rate.
reg_season_details <- reg_season_details %>%
    mutate(Wpossessions = round(0.96 * ((WFGA) - (WOR) + (WTO) + (0.44 * WFTA))), # https://www.nbastuffer.com/analytics101/possession/
           Lpossessions = round(0.96 * ((LFGA) - (LOR) + (LTO) + (0.44 * LFTA))),
           average_tempo = (Wpossessions + Lpossessions) / 2,
           ########## WINNING TEAM's derived statistics ########## 
           # points scored per 100 possessions on offense by winning team. 
           Woffense_efficiency = 100 * (WScore / Wpossessions),
           # points allowed per 100 possessions on defense by winning team.  
           Wdefense_efficiency = 100 * (LScore / Lpossessions),
           # difference in offense vs. defensive pts per 100 possessions
           Wnet_efficiency_ratio = round(((Woffense_efficiency / Wdefense_efficiency) -1), 3),
           Wscore_diff = WScore - LScore,
           # more offense related
           Wassist_to_fgm_ratio = WAst / WFGM,
           Weffective_fg_rate = (WFGM + (0.5 * WFGM3)) / WFGA,
           # Rebounding factors
           WORB_rate = WOR / (WOR + LDR),
           WDRB_rate = WDR / (LOR + WDR),
           # free throw factor
           WFT_rate = WFTA / WFGA,
           WFTM_pct = WFTM / WFTA,
           # Turnover factor: turnovers per 100 possessions.
           Woffense_tov_per_100 = 100 *(WTO / (WFGA + (0.44 * WFTA) + WTO)),
           # Winner's defense stats. based on how the losing team performed in game. 
           Wdefense_effective_fg_rate = (LFGM + (0.5 * LFGM3)) / LFGA,
           Wdefense_FT_rate = LFTA / LFGA,
           Wdefense_tov_per_100 = 100 *(LTO / (LFGA + (0.44 * LFTA) + LTO)),
           Wopponent_ORB_rate = LOR / (LOR + WDR),
           Wopponent_DRB_rate = LDR / (WOR + LDR),
           ########## LOSING TEAM's derived statistics ########## 
           Loffense_efficiency = 100 * (LScore / Lpossessions),
           Ldefense_efficiency = 100 * (WScore / Wpossessions),
           Lnet_efficiency_ratio = round(((Loffense_efficiency / Ldefense_efficiency) -1), 3),
           Lscore_diff = LScore - WScore,
           Lassist_to_fgm_ratio = LAst / LFGM,
           Leffective_fg_rate = (LFGM + (0.5 * LFGM3)) / LFGA,
           LORB_rate = LOR / (LOR + WDR),
           LDRB_rate = LDR / (WOR + LDR),
           LFT_rate = LFTA / LFGA,
           LFTM_pct = LFTM / LFTA,
           Loffense_tov_per_100 = 100 *(LTO / (LFGA + (0.44 * LFTA) + LTO)),
           Ldefense_effective_fg_rate = (WFGM + (0.5 * WFGM3)) / WFGA,
           Ldefense_FT_rate = WFTA / WFGA,
           Ldefense_tov_per_100 = 100 *(WTO / (WFGA + (0.44 * WFTA) + WTO)),
           Lopponent_ORB_rate = WOR / (WOR + LDR), 
           Lopponent_DRB_rate = WDR / (LOR + WDR)
)
```

In order to properly start computing 1-game lag team summary stats leading up to every game in a given season, the data needs to be restructured from the currently untidy wide format. Data from both teams playing a game currently exist in one row, with similar variables (ex. FGM) spread across multiple columns. Thankfully, it's known that a given team's box score data will be in the prefixed **W** columns when they won, in the prefixed **L** columns for the game row where they lost. Their opponents would just be in the adjacent and oppositely prefixed columns. 

For good data pre-processing of team cumulative summary statistics prior to each game, I need each row to represent every unique game played by every team so I can compute these cumulating summary statistics
for all their games (wins & losses) in season. 

``` {r feature_creating, echo = TRUE}
reg_season_details_winner <- reg_season_details %>%
    select(game_id, Season, DayNum, starts_with("W"), average_tempo) %>%
    rename_at(vars(starts_with("W")), # for columns starting with W
              function(x) stringr::str_sub(x, start = 2L, end = -1L)) %>% # strip W off column name.
    mutate(outcome = "W",
           outcome_1_0 = 1)
    

reg_season_details_loser <- reg_season_details %>%
    # need to create variable that codes the game location of the losing team, since the variable "Wloc" only codes winning team
    mutate(LLoc = ifelse(WLoc == "A", "H",
                         ifelse(WLoc == "H", "A", "N"))) %>%
    select(game_id, Season, DayNum, starts_with("L"), average_tempo) %>%
    rename_at(vars(starts_with("L")), # for columns starting with L
              function(x) stringr::str_sub(x, start = 2L, end = -1L)) %>% # strip off L. 
    mutate(outcome = "L",
           outcome_1_0 = 0)

# stack dataframes on top each other, sort by 
reg_season_details_long <- bind_rows(reg_season_details_winner,
                                         reg_season_details_loser) %>%
    arrange(TeamID, Season, DayNum)
```


###  Convert per game stats to lagging team performance features
 
Given the per game summary measures previously created, I can now create initial predictors that represent 1-game lag summaries of team's season performance leading up to the game date in question. 


``` {r feature_creating, echo = FALSE}
reg_season_details_cumulative_stats <- reg_season_details_long %>%
    group_by(Team_name, Season) %>%
    # sort each team's game (row) chronological order
    arrange(Team_name, Season, DayNum) %>% 
    # these are 1 game lag cumulative averages, per team per season. I average each team’s stats by game (equal weighting by game). 
    mutate(season_wins = lag(cumsum(outcome_1_0)), # default lag of n = 1 prior period.
           season_win_rate = season_wins / lag(row_number()),
           possessions = lag(cummean(possessions)), 
           average_tempo = lag(cummean(average_tempo)),
           offense_efficiency = lag(cummean(offense_efficiency)),
           defense_efficiency = lag(cummean(defense_efficiency)),
           net_efficiency_ratio = lag(cummean(net_efficiency_ratio)),
           score_diff = lag(cummean(score_diff)),
           assist_to_fgm_ratio = lag(cummean(assist_to_fgm_ratio)),
           effective_fg_rate = lag(cummean(effective_fg_rate)),
           ORB_rate = lag(cummean(ORB_rate)),
           DRB_rate = lag(cummean(DRB_rate)),
           FT_rate = lag(cummean(FT_rate)),
           FTM_pct = lag(cummean(FTM_pct)),
           offense_tov_per_100 = lag(cummean(offense_tov_per_100)),
           defense_effective_fg_rate = lag(cummean(defense_effective_fg_rate)),
           defense_FT_rate = lag(cummean(defense_FT_rate)),
           defense_tov_per_100 = lag(cummean(defense_tov_per_100)),
           opponent_ORB_rate = lag(cummean(opponent_ORB_rate)),
           opponent_DRB_rate = lag(cummean(opponent_DRB_rate))
           ) %>%
    select(1:6, outcome, outcome_1_0, everything())
    
###### Data Checks #########
 reg_season_details_long %>% 
     filter(Team_name == "Loyola-Chicago" & Season == 2017) %>% 
     select(1:6, 22:41) %>%
     View()

reg_season_details_cumulative_stats %>%
    filter(Team_name == "Loyola-Chicago" & Season == 2017) %>%
    select(1:8, 24:43) %>%
     View()

 
loyola17_game_stats <- filter(reg_season_details_long, Team_name == "Loyola-Chicago" & Season == 2017)
mean(loyola17_game_stats$effective_fg_rate[1:29]) # this agrees with the value in reg_season_details_cumulative_stats on last game of season.

filter(reg_season_details_cumulative_stats, Team_name == "Loyola-Chicago" & Season == 2017) %>%
    inner_join(reg_season_details_cumulative_stats, by = "game_id") %>% 
    filter(Team_name.x != Team_name.y) %>%
    arrange(Season.x, DayNum.x) %>%
    View()

```

### Consider Matchup Differences

Matchup Differentials: Algorithms that treat bracketology as a ranking problem assume that the transitive property applies to head to head match ups for teams in the tournament that likely haven't played each other before or often. If team A is > team B on an index score, and team C > A on this scoring system, then team C > team B and we predict team C to win. Generally, this may be a good heuristic that [generally holds up](https://www.theplayerstribune.com/math-meets-football-the-transitive-property-is-real/), but I'm positing that this could be problematic for modeling the potential of an **upset**. We're not considering how well team B and team C match up individually with each other. For instance, a feature may be the difference in the shooting efficiency of team C from team B heading into a game. Perhaps this gives one team a matchup edge over another, which can be measured for a signal in the trained model. 

## Feature Exploration

WORK IN PROGRESS. Not sure if I'll publish these findings. 
