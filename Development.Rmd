---
title: "Develop Initial Model"
author: "Brandon Hoeft"
date: "March 3, 2018"
output:
  github_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = "",
                      fig.height = 6, fig.width = 6)
options(scipen=999) # turn of scientific notation.
library(pryr) # mem_used() and object_size() functions to manage/understand memory usage.

```

## Overview

A lot of the work in this initial analysis will be structured around wrangling data provided by Google and NCAA for the [Google Cloud & NCAA® ML Competition 2018 Men's](https://www.kaggle.com/c/mens-machine-learning-competition-2018), building initial features, and training/testing a minimum viable model for predicting outcomes of NCAA basketball games. 

Research into initial features for a predictive model have been informed by advanced NBA statistics derived from traditional box score data, which was made available by the competition sponsors. 

Goals of the competition are two-fold:

**1**: You should submit predicted probabilities for every possible matchup in the past 4 NCAA® tournaments (2014-2017).

**2**: You should submit predicted probabilities for every possible matchup before the 2018 tournament begins.

## Data

I'm primarily working with the dataset called *RegularSeasonDetailedResults.csv*, which has detailed aggregate box score stats for every game for each team played. See the [data dictionary](https://www.kaggle.com/c/mens-machine-learning-competition-2018/data) for more details. 

``` {r data_import, echo = FALSE}
library(aws.s3)
library(readr)
library(dplyr)
# specify personal account keys as environment variables so I can read my s3 object(s) from AWS. 
# DO NOT SAVE KEY in code or render in output!!!! Could compromise AWS account. 
# Note to self my key and secret last gen from October 2017. 
#Sys.setenv("AWS_ACCESS_KEY_ID" = "",
#           "AWS_SECRET_ACCESS_KEY" = "")

RegularSeasonDetailedResults <- s3read_using(FUN = read_csv, 
                      object = "RegularSeasonDetailedResults.csv",
                      bucket = "ncaabasketball")

team_conference <- s3read_using(FUN = read_csv, 
                      object = "TeamConferences.csv",
                      bucket = "ncaabasketball")

team_name <- s3read_using(FUN = read_csv, 
                      object = "Teams.csv",
                      bucket = "ncaabasketball")

# Massey Rankings website.
#rankings <- s3read_using(FUN = read_csv, 
#                      object = "MasseyOrdinals.csv",
#                      bucket = "ncaabasketball")

# https://fivethirtyeight.blogs.nytimes.com/2011/03/14/how-we-made-our-n-c-a-a-picks/
#rankings <- rankings %>%
#    filter(SystemName %in% c("POM", # Pomeroy
#                             "SAG", # Sagarin (USA Today)
#                             "RPI")) # Rating % Index. Accounts for Strength of Schedule. 

# detailed box score results data for all NCAA Tournament games 2003 - 2017
NCAATourneyDetailedResults <- s3read_using(FUN = read_csv, 
                      object = "NCAATourneyDetailedResults.csv",
                      bucket = "ncaabasketball")

# detailed box score results data for all regular season NCAA D1 games 2003 - 2017
reg_season_details <- RegularSeasonDetailedResults %>%
    # conference of winning team.
    left_join(team_conference, by = c("WTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of winning team.
    left_join(team_name, by = c("WTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(WTeam_conf = ConfAbbrev,
           WTeam_name = TeamName) %>%
    # conference of losing team.
    left_join(team_conference, by = c("LTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of losing team.
    left_join(team_name, by = c("LTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(LTeam_conf = ConfAbbrev,
           LTeam_name = TeamName) %>%
    select(Season, DayNum, WTeamID, WTeam_name, WTeam_conf, WScore,
           LTeamID, LTeam_name, LTeam_conf, LScore, everything())

glimpse(reg_season_details)
```

Due to the data wrangling that will follow, we may need an identifier of each specific game matchup. To create completely unique game ID's, we need a combination of the Season, day, winning team id, losing team id. From my inspection, omitting the *day* from the game ID string creates duplicates as teams may play each other multiple times in a season where the Winning and Losing team were the same. 

``` {r game_id, echo = TRUE}
reg_season_details <- reg_season_details %>%
    mutate(game_id = paste(Season, DayNum, WTeamID, LTeamID, sep = "_")) %>%
    select(game_id, everything())
    
# check unique. Should have value of 1. 
reg_season_details %>%
    group_by(game_id) %>%
    summarize(frequency = n()) %>%
    arrange(desc(frequency)) %>% slice(1:5)
```

## Data Wrangling

For the game data to be potentially useful in predicting the outcomes of games, the inputs cannot have [data leakage](https://www.kaggle.com/wiki/Leakage). 

*  **simplest approach**: create features that represent regular season summary aggregates as predictors for each team in the NCAA tournament. Use all outcomes of NCAA tournament games from 2003-2013 as target. 

*  **better approach**: create features that are cumulative aggregates throughought the course of the regular season. As such, training observations can be basically every single game outcome from the regular season, with the features in each row representing the rolling, aggregate summary stats of the team as of the day of the season prior to the exam. This enables much more training records to build a model off of. To test the model, we'll still use the aggregate features as of the last day of the regular season, as inputs to predict tournament performance. 

In order to properly start computing lagging aggregate summary stats prior to every game, the data needs to be restructured from its very untidy wide format. Data from both teams playing a game are in one row, with similar variables (ex. FGM) spread across multiple columns. A given team's summary data will sometimes be in the prefixed **W** columns when they won, but other times their summary data will be in the prefixed **L** columns from their losses. 

However, for good data pre-processing, I need each row to represent every game played by every team. 
``` {r feature_creating, echo = TRUE}
reg_season_details_winner <- reg_season_details %>%
    mutate(WScore_diff = WScore - LScore) %>%
    select(game_id, Season, DayNum, starts_with("W")) %>%
    rename_at(vars(starts_with("W")), # for columns starting with W
              function(x) stringr::str_sub(x, start = 2L, end = -1L)) %>% # strip W off column name.
    mutate(outcome = "W",
           outcome_1_0 = 1)
    

reg_season_details_loser <- reg_season_details %>%
    # need to create variable that codes the game location of the losing team, since the variable "Wloc" only codes winning team
    mutate(LScore_diff = LScore - WScore,
           LLoc = ifelse(WLoc == "A", "H",
                         ifelse(WLoc == "H", "A", "N"))) %>%
    select(game_id, Season, DayNum, starts_with("L")) %>%
    rename_at(vars(starts_with("L")), # for columns starting with L
              function(x) stringr::str_sub(x, start = 2L, end = -1L)) %>% # strip off L. 
    mutate(outcome = "L",
           outcome_1_0 = 0)

# stack dataframes on top each other, sort by 
reg_season_details_long <- bind_rows(reg_season_details_winner,
                                         reg_season_details_loser) %>%
    arrange(TeamID, Season, DayNum)

```


### Feature Creation 

Some initial predictors I am considering developing, which will be lagging aggregates of team and opponent performance will primarily focus on rate type metrics, as opposed to counting statistics. The former remove the bias of context such as playing style/tempo, which contribute towards noise in counting stats (ex. total points, total 3p made, etc). Some examples include

*  Points per Possession (PPP):  this is an offensive efficiency metric. 

*  Defensive Points per Possession (dPPP): this is a  defensive efficiency metric.

*  Dean Oliver's [Four Factors](https://www.basketball-reference.com/about/factors.html): concepts from a noteworthy basketball statistician's factors for basketball success. I will consider accounting for shooting efficiency, turnovers, rebounding, and free throw performance. 

*  Matchup Differentials: Algorithms that treat bracketology as a ranking problem assume that the transitive property applies to head to head match ups for teams in the tournament that likely haven't played each other before or often. If team A is > team B on an index score, and team C > A on this scoring system, then team C > team B and we predict team C to win. Generally, this may be a good heuristic that [generally holds up](https://www.theplayerstribune.com/math-meets-football-the-transitive-property-is-real/), but I'm positing that this could be problematic for modeling the potential of an **upset**. We're not considering how well team B and team C match up individually with each other. For instance, a feature may be the difference in the shooting efficiency of team C from team B heading into a game. Perhaps this gives one team a matchup edge over another, which can be measured for a signal in the trained model.  

Any features built for the model that are called "percentage" are really just a proportion (0-1 scale). Percentage is used as it is a common parlance for sports statistics as opposed to proportion. However, it's still good to be aware that .500 season win rate means 50% win rate and not .50% win rate with these data.  

 **NEXT FEATURES: ORB%, DRB%, Turnover% (defense) **
 
``` {r feature_creating, echo = FALSE}
reg_season_details_long_features <- reg_season_details_long %>%
    mutate(possessions = round(0.96 * ((FGA) - (OR) + (TO) + (0.44 * FTA)))) %>% # https://www.nbastuffer.com/analytics101/possession/
    # conduct analysis within Season for each team
    group_by(Team_name, Season) %>%
    # sort each team's game (row) chronological order
    arrange(Team_name, Season, DayNum) %>%
    # these are 1 game lag cumulative average stats, within season, per team. Unweighted averages. They ARE NOT equally weighted per game the way Pomeroy does it. 
    mutate(tempo = lag(cummean(possessions)), # avg. possessions per game. 
           # points per 100 possessions on offense. 
           offense_efficiency = 100 * (lag(cumsum(Score)) / lag(cumsum(possessions))),
           # points per 100 possessions on defense.  
           defense_efficiency = 100 * (lag(cumsum(Score - Score_diff)) / lag(cumsum(possessions))),
           # cumulative % difference in offense vs. defensive pts per 100 possessions
           net_efficiency_pct = round(((offense_efficiency / defense_efficiency) -1), 3),
           avg_score_diff = lag(cummean(Score_diff)),
           season_wins = lag(cumsum(outcome_1_0)),
           season_win_rate = season_wins / lag(row_number()),
           # more offens related
           assist_to_fgm_ratio = lag(cumsum(Ast)) / lag(cumsum(FGM)),
           effective_fg_pct = (lag(cumsum(FGM)) + lag(cumsum(0.5 * FGM3))) / lag(cumsum(FGA), 1),
           # free throw factor
           FTA_to_FGA = lag(cumsum(FTA)) / lag(cumsum(FGA)),
           FTM_pct = lag(cumsum(FTM)) / lag(cumsum(FTA)),
           # Turnover factor: turnovers per 100 possessions.
           tov_per_100 = 100 *(lag(cumsum(TO)) / (lag(cumsum(FGA)) + lag(cumsum(0.44 * FTA)) + lag(cumsum(TO))))
           ) %>%
    select(-possessions)




reg_season_details_long_features %>% filter(Team_name == "Loyola-Chicago") %>% View()



temp <- reg_season_details_long %>%
    filter(Team_name == c("Loyola-Chicago")) %>%
    # https://www.nbastuffer.com/analytics101/possession/
    mutate(possessions = round(0.96 * ((FGA) - (OR) + (TO) + (0.44 * FTA)))) %>%
    group_by(Team_name, Season) %>%
    arrange(Team_name, Season, DayNum) %>%
    # these are 1 game lag cumulative average stats, within season, per team. Unweighted averages. They ARE NOT equally weighted per game the way Pomeroy does it. 
    mutate(tempo = lag(cummean(possessions)),
           # points per 100 possessions on offense. 
           offense_efficiency = 100 * (lag(cumsum(Score)) / lag(cumsum(possessions))),
           # points per 100 possessions on defense.  
           defense_efficiency = 100 * (lag(cumsum(Score - Score_diff)) / lag(cumsum(possessions))),
           # cumulative % difference in offense vs. defensive pts per 100 possessions
           net_efficiency_pct = round(((offense_efficiency / defense_efficiency) -1), 3),
           avg_score_diff = lag(cummean(Score_diff)),
           season_wins = lag(cumsum(outcome_1_0)),
           season_win_rate = season_wins / lag(row_number()),
           # more offens related
           assist_to_fgm_ratio = lag(cumsum(Ast)) / lag(cumsum(FGM)),
           effective_fg_pct = (lag(cumsum(FGM)) + lag(cumsum(0.5 * FGM3))) / lag(cumsum(FGA), 1),
           # free throw factor
           FTA_to_FGA = lag(cumsum(FTA)) / lag(cumsum(FGA)),
           FTM_pct = lag(cumsum(FTM)) / lag(cumsum(FTA)),
           # Turnover factor: turnovers per 100 possessions.
           tov_per_100 = 100 *(lag(cumsum(TO)) / (lag(cumsum(FGA)) + lag(cumsum(0.44 * FTA)) + lag(cumsum(TO))))
           )


temp %>%
    filter(Season == 2017) %>% 
    select(1:6, TO, FGA, FTA, tov_per_100) %>% View()

temp3 <- filter(temp2, Season == 2017 & DayNum %in% 11:50)
mean(temp3$avg_ppp_offense, na.rm = TRUE)
```


## Feature Exploration

WORK IN PROGRESS. Not sure if I'll publish these findings. 
