---
title: "Develop Initial Model"
author: "Brandon Hoeft"
date: "March 3, 2018"
output:
  github_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = "",
                      fig.height = 6, fig.width = 6)
options(scipen=999) # turn of scientific notation.
library(pryr) # mem_used() and object_size() functions to manage/understand memory usage.

```

## Overview

The work in this analysis will be structured around wrangling data provided by Google and NCAA for the [Google Cloud & NCAA® ML Competition 2018 Men's](https://www.kaggle.com/c/mens-machine-learning-competition-2018), building initial features, and training/testing a minimum viable model for predicting outcomes of NCAA basketball games. 

Research into initial features for a predictive model have been informed by advanced NBA statistics derived from traditional box score data, which was made available by the competition sponsors. 

Goals of the competition are two-fold:

**1**: You should submit predicted probabilities for every possible matchup in the past 4 NCAA® tournaments (2014-2017).

**2**: You should submit predicted probabilities for every possible matchup before the 2018 tournament begins.

## Data

I'm primarily working with the dataset called *RegularSeasonDetailedResults.csv*, which has detailed aggregate box score stats for every game for each team played. See the [data dictionary](https://www.kaggle.com/c/mens-machine-learning-competition-2018/data) for more details. The data is structured in such a way that each row represents a single game between two teams with columns representing box score statistics for each the winning and the losing team.

``` {r data_import, echo = FALSE}
library(aws.s3)
library(readr)
library(dplyr)
# specify personal account keys as environment variables so I can read my s3 object(s) from AWS. 
# DO NOT SAVE KEY in code or render in output!!!! Could compromise AWS account. 
# Note to self my key and secret last gen from October 2017. 
#Sys.setenv("AWS_ACCESS_KEY_ID" = "",
#           "AWS_SECRET_ACCESS_KEY" = "")

RegularSeasonDetailedResults_Prelim2018 <- s3read_using(FUN = read_csv, 
                      object = "RegularSeasonDetailedResults_Prelim2018.csv",
                      bucket = "ncaabasketball") %>%
    mutate(tournament_type = "regular season") %>%
    select(tournament_type, everything())


team_conference <- s3read_using(FUN = read_csv, 
                      object = "TeamConferences.csv",
                      bucket = "ncaabasketball")

team_name <- s3read_using(FUN = read_csv, 
                      object = "Teams.csv",
                      bucket = "ncaabasketball")

# detailed box score results data for all NCAA Tournament games 2003 - 2017
NCAATourneyDetailedResults_Pre2018 <- s3read_using(FUN = read_csv, 
                      object = "NCAATourneyDetailedResults.csv",
                      bucket = "ncaabasketball") %>%
    mutate(tournament_type = "NCAA Tournament") %>%
    select(tournament_type, everything())

# detailed box score results data for all regular season NCAA D1 games 2003 - 2017
reg_season_details <- RegularSeasonDetailedResults_Prelim2018 %>%
    bind_rows(NCAATourneyDetailedResults_Pre2018) %>%
    # conference of winning team.
    left_join(team_conference, by = c("WTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of winning team.
    left_join(team_name, by = c("WTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>% # remove other cols from team_name
    rename(WTeam_conf = ConfAbbrev,
           WTeam_name = TeamName) %>%
    # conference of losing team.
    left_join(team_conference, by = c("LTeamID" = "TeamID",
                                      "Season" = "Season")) %>%
    # name of losing team.
    left_join(team_name, by = c("LTeamID" = "TeamID")) %>%
    select(-contains("D1Season")) %>%
    rename(LTeam_conf = ConfAbbrev,
           LTeam_name = TeamName) %>%
    select(tournament_type, Season, DayNum, WTeamID, WTeam_name, WTeam_conf, WScore,
           LTeamID, LTeam_name, LTeam_conf, LScore, everything())

glimpse(reg_season_details)
```

Additionally, I need to wrangle the team ratings data provided by Massey's website. Ratings have been normalized by the competition sponsor to be ordinal rankings instead. Per the definition of the competition of RankingDayNum: *this integer always ranges from 0 to 133, and is expressed in the same terms as a game's DayNum (where DayZero is found in the Seasons.csv file). The RankingDayNum is intended to tell you the first day that it is appropriate to use the rankings for predicting games. For example, if RankingDayNum is 110, then the rankings ought to be based upon game outcomes up through DayNum=109, and so you can use the rankings to make predictions of games on DayNum=110 or later. The final pre-tournament rankings each year have a RankingDayNum of 133, and can thus be used to make predictions of the games from the NCAA® tournament, which start on DayNum=134 (the Tuesday after Selection Sunday).*

An example below is the rankings data available for using to predict game outcomes for Loyola Chicago's 2018 season. But these RankingDayNum values don't correspond to actual DayNum of every game Loyola Chicago played, which creates a problem. They more or less reflect the day in the season that the rating is useful for prediction as of. 

```{r echo = FALSE}
team_ratings <- s3read_using(FUN = read_csv, 
                      object = "MasseyOrdinals_sag_pom_rpi_Prelim2018.csv",
                      bucket = "ncaabasketball") %>%
    tidyr::spread(SystemName, OrdinalRank)

team_ratings %>%
    filter(TeamID == 1260 & Season == 2018) %>% 
    arrange(Season, RankingDayNum) %>%
    kable()
```

Since the RankingDayNum does not match exactly with the DayNum from the box score data, a grid needs to be built that has every combination of possible TeamID, Season, DayNum (1-133). Additional Days are created through Day 154 too, so that NCAA tournament games can carry forward their rankings from last publishing at regular season's end.

Then for each DayNum of a TeamID's Season, we can replace DayNum rows that don't have a team rating as of the specific RankingDayNum, by replacing this missing value with the latest non-missing value using the `zoo` library.

As an example output, we can see how Loyola Chicago's running ratings for the last 3-weeks of data available for the 2018 season reflect their rating on every single day now. This makes it easy for joining these data to the actual game outcome we'll be modeling later.  
``` {r}
# all possible combinations of teamID,Season,Day from 1-133
team_season_day_grid <- expand.grid(Season = 2003:2018,
                                    RankingDayNum = 1:154, # 154 is the last day of NCAA tourney. 
                                    TeamID = unique(team_ratings$TeamID)) %>%
    arrange(TeamID, Season, RankingDayNum)

team_ratings_all_days <- team_season_day_grid %>%
    left_join(team_ratings, by = c("Season", "RankingDayNum", "TeamID")) %>%
    select(Season, RankingDayNum, TeamID, POM, RPI, SAG) %>%
    group_by(TeamID, Season) %>%
    arrange(TeamID, Season, RankingDayNum) %>% 
    # http://www.markhneedham.com/blog/2015/06/28/r-dplyr-update-rows-with-earlierprevious-rows-values/
    do(zoo::na.locf(.))

team_ratings_all_days %>%
    filter(TeamID == 1260 & Season == 2018 & RankingDayNum %in% 99:116) %>% 
    arrange(Season, RankingDayNum) %>%
    kable()

# Actualy RPI as of end of 2018 season. 
#team_ratings_all_days %>%
#    filter(Season == 2018, RankingDayNum == 133) %>%
#    arrange(RPI) %>% 
#    kable()
```

Having pre-processed the rankings data for each team in each season for every day of that season,  I need to combine that with the game data, so we can know what each team and it's opponent's ranking (Pomeroy, Sagarin, RPI) was going into that matchup. 

``` {r}
reg_season_details <- reg_season_details %>%
    # rankings of the WINNING team heading into each game day.
    left_join(team_ratings_all_days, by = c("WTeamID" = "TeamID",
                                            "Season" = "Season",
                                            "DayNum" = "RankingDayNum")) %>%
    rename(WPOM_rank = POM,
           WRPI_rank = RPI,
           WSAG_rank = SAG) %>%
    # rankings of the LOSING team heading into each game day.
    left_join(team_ratings_all_days, by = c("LTeamID" = "TeamID",
                                            "Season" = "Season",
                                            "DayNum" = "RankingDayNum")) %>%
    rename(LPOM_rank = POM,
           LRPI_rank = RPI,
           LSAG_rank = SAG)
```

Due to the data wrangling that will follow, I created a unique game identifier of each specific game matchup by concatenating the Season, DayNum, WTeamID, LTeamID. From my inspection, omitting the *day* from the game ID string creates duplicates as teams may play each other multiple times in a season where the Winning and Losing team were the same. These games represent all regular season games and any conference tournament games played at the end of the regular season. 

``` {r game_id, echo = TRUE}
reg_season_details <- reg_season_details %>%
    mutate(game_id = paste(Season, DayNum, WTeamID, LTeamID, sep = "_")) %>%
    select(game_id, everything())
    
# check unique. Should have value of 1. 
reg_season_details %>%
    group_by(game_id) %>%
    summarize(frequency = n()) %>%
    arrange(desc(frequency)) %>% slice(1:5)
```

## Data Wrangling Approach

For the game data to be potentially useful in predicting the outcomes of games, the inputs cannot have [data leakage](https://www.kaggle.com/wiki/Leakage). 

*  **simplest approach**: create features that represent regular season summary aggregates as predictors for each team that exist in the NCAA tournament from 2003-2017. Use all games of NCAA tournament games from 2003-2013 to train a model. 

*  **better approach**: create features that are cumulative 1-day lag summary statistics measured over the course of each team's regular season. As such, training observations can be any single game outcome from the regular season. The features in each row could represent in-season summary stats leading up to the game day in question. This enables much more training records to build a model off of. To test the model, we'll still use the aggregate features as of the last day of the regular season, as inputs to predict that season's NCAA tournament performance. 

### Per game Rate/Efficiency Measurements 

Some of the first things I want to create from the data in *RegularSeasonDetailedResults.csv* is to capture rate and efficiency based statistics (as opposed to frequency or count stats) about the the winning team and the losing team of each game. Frequency or count based stats are known to be filled with bias that add too much noise *For example, a team's very high points per game might be a function of a fast paced playing style, and not because they're efficient or good shooters.* These initial measures are not going to be predictors in a model, but are the first step towards creating predictors/features. 

Some examples and other sources of inspiration include:

*  Points per Possession (PPP):  this is an offensive efficiency metric adjusted to per 100 possessions. 
*  Defensive Points per Possession (dPPP): this is a  defensive efficiency metric to per 100 possessions.

*  Dean Oliver's [Four Factors](https://www.basketball-reference.com/about/factors.html): concepts from a noteworthy basketball statistician's factors for basketball success. Areas to consider include shooting, rebounding, turnovers, free throws. 

* Efficiency type metrics as published by [Ken Pomeroy](https://kenpom.com/blog/ratings-glossary/)

```{r}

# get opponent stats so we can calculate defensive effective FG% (FGM, FGM3, FGA), defensive TO%, defensive ORB%, defensive FT rate.
reg_season_details <- reg_season_details %>%
    mutate(Wpossessions = round(0.96 * ((WFGA) - (WOR) + (WTO) + (0.44 * WFTA))), # https://www.nbastuffer.com/analytics101/possession/
           Lpossessions = round(0.96 * ((LFGA) - (LOR) + (LTO) + (0.44 * LFTA))),
           average_tempo = (Wpossessions + Lpossessions) / 2,
           ########## WINNING TEAM's derived statistics ########## 
           # points scored per 100 possessions on offense by winning team. 
           Woffense_efficiency = 100 * (WScore / Wpossessions),
           # points allowed per 100 possessions on defense by winning team.  
           Wdefense_efficiency = 100 * (LScore / Lpossessions),
           # difference in offense vs. defensive pts per 100 possessions
           Wnet_efficiency_ratio = round(((Woffense_efficiency / Wdefense_efficiency) -1), 3),
           Wscore_diff = WScore - LScore,
           # more offense related
           Wassist_to_fgm_ratio = WAst / WFGM,
           Weffective_fg_rate = (WFGM + (0.5 * WFGM3)) / WFGA,
           # Rebounding factors
           WORB_rate = WOR / (WOR + LDR),
           WDRB_rate = WDR / (LOR + WDR),
           # free throw factor
           WFT_rate = WFTA / WFGA,
           WFTM_pct = ifelse(is.nan(WFTM / WFTA), .689, WFTM / WFTA),
           # Turnover factor: turnovers per 100 possessions.
           Woffense_tov_per_100 = 100 *(WTO / (WFGA + (0.44 * WFTA) + WTO)),
           # Winner's defense stats. based on how the losing team performed in game. 
           Wdefense_effective_fg_rate = (LFGM + (0.5 * LFGM3)) / LFGA,
           Wdefense_FT_rate = LFTA / LFGA,
           Wdefense_tov_per_100 = 100 *(LTO / (LFGA + (0.44 * LFTA) + LTO)),
           Wopponent_ORB_rate = LOR / (LOR + WDR),
           Wopponent_DRB_rate = LDR / (WOR + LDR),
           # Foul Factors
           WPF_drawn_pg = LPF,
           WPF_committed_pg = WPF,  
           ########## LOSING TEAM's derived statistics ########## 
           Loffense_efficiency = 100 * (LScore / Lpossessions),
           Ldefense_efficiency = 100 * (WScore / Wpossessions),
           Lnet_efficiency_ratio = round(((Loffense_efficiency / Ldefense_efficiency) -1), 3),
           Lscore_diff = LScore - WScore,
           Lassist_to_fgm_ratio = LAst / LFGM,
           Leffective_fg_rate = (LFGM + (0.5 * LFGM3)) / LFGA,
           LORB_rate = LOR / (LOR + WDR),
           LDRB_rate = LDR / (WOR + LDR),
           LFT_rate = LFTA / LFGA,
           LFTM_pct = ifelse(is.nan(LFTM / LFTA), .689, LFTM / LFTA),
           Loffense_tov_per_100 = 100 *(LTO / (LFGA + (0.44 * LFTA) + LTO)),
           Ldefense_effective_fg_rate = (WFGM + (0.5 * WFGM3)) / WFGA,
           Ldefense_FT_rate = WFTA / WFGA,
           Ldefense_tov_per_100 = 100 *(WTO / (WFGA + (0.44 * WFTA) + WTO)),
           Lopponent_ORB_rate = WOR / (WOR + LDR), 
           Lopponent_DRB_rate = WDR / (LOR + WDR),
           LPF_drawn_pg = WPF,
           LPF_committed_pg = LPF)
```

In order to properly start computing 1-game lag team summary stats leading up to every game in a given season, the data needs to be restructured from the currently untidy wide format. Data from both teams playing a game currently exist in one row, with similar variables (ex. FGM) spread across multiple columns. Thankfully, it's known that a given team's box score data will be in the prefixed **W** columns when they won, in the prefixed **L** columns for the game row where they lost. Their opponents would just be in the adjacent and oppositely prefixed columns. 

For good data pre-processing of team cumulative summary statistics prior to each game, I need each row to represent every unique game played by every team so I can compute these cumulating summary statistics
for all their games (wins & losses) in season. 

``` {r feature_creating, echo = TRUE}
reg_season_details_winner <- reg_season_details %>%
    select(game_id, tournament_type, Season, DayNum, starts_with("W"), average_tempo) %>%
    rename_at(vars(starts_with("W")), # for columns starting with W
              function(x) stringr::str_sub(x, start = 2L, end = -1L)) %>% # strip W off column name.
    mutate(outcome = "W",
           outcome_1_0 = 1)
    

reg_season_details_loser <- reg_season_details %>%
    # need to create variable that codes the game location of the losing team, since the variable "Wloc" only codes winning team
    mutate(LLoc = ifelse(WLoc == "A", "H",
                         ifelse(WLoc == "H", "A", "N"))) %>%
    select(game_id, tournament_type, Season, DayNum, starts_with("L"), average_tempo) %>%
    rename_at(vars(starts_with("L")), # for columns starting with L
              function(x) stringr::str_sub(x, start = 2L, end = -1L)) %>% # strip off L. 
    mutate(outcome = "L",
           outcome_1_0 = 0)

# stack dataframes on top each other, sort by 
reg_season_details_long <- bind_rows(reg_season_details_winner,
                                         reg_season_details_loser) %>%
    arrange(TeamID, Season, DayNum)
```


###  Convert per game stats to lagging team performance features
 
Given the per game summary measures previously created, I can now create initial predictors that represent 1-game lag summaries of team's season performance leading up to the game they were involved in. 


``` {r feature_creating, echo = FALSE}
reg_season_details_cumulative_stats <- reg_season_details_long %>%
    group_by(Team_name, Season) %>%
    # sort each team's game (row) chronological order
    arrange(Team_name, Season, DayNum) %>% 
    # these are 1 game lag cumulative averages, per team per season. I average each team’s stats by game (equal weighting by game). 
    mutate(season_wins = lag(cumsum(outcome_1_0)), # default lag of n = 1 prior period.
           season_win_rate = season_wins / lag(row_number()),
           possessions = lag(cummean(possessions)), 
           average_tempo = lag(cummean(average_tempo)),
           offense_efficiency = lag(cummean(offense_efficiency)),
           defense_efficiency = lag(cummean(defense_efficiency)),
           net_efficiency_ratio = lag(cummean(net_efficiency_ratio)),
           score_diff = lag(cummean(score_diff)),
           assist_to_fgm_ratio = lag(cummean(assist_to_fgm_ratio)),
           effective_fg_rate = lag(cummean(effective_fg_rate)),
           ORB_rate = lag(cummean(ORB_rate)),
           DRB_rate = lag(cummean(DRB_rate)),
           FT_rate = lag(cummean(FT_rate)),
           FTM_pct = lag(cummean(FTM_pct)),
           offense_tov_per_100 = lag(cummean(offense_tov_per_100)),
           defense_effective_fg_rate = lag(cummean(defense_effective_fg_rate)),
           defense_FT_rate = lag(cummean(defense_FT_rate)),
           defense_tov_per_100 = lag(cummean(defense_tov_per_100)),
           opponent_ORB_rate = lag(cummean(opponent_ORB_rate)),
           opponent_DRB_rate = lag(cummean(opponent_DRB_rate)),
           PF_drawn_pg = lag(cummean(PF_drawn_pg)), 
           PF_committed_pg = lag(cummean(PF_committed_pg))) %>%
    select(1:7, outcome, outcome_1_0, everything()) %>%
    ungroup()
```

``` {r datachecks, include = FALSE, eval = FALSE}
###### Data Checks #########
 reg_season_details_long %>% 
     filter(Team_name == "Loyola-Chicago" & Season == 2017) %>% 
     select(1:6, 22:43) %>%
     View()

reg_season_details_cumulative_stats %>%
    filter(Team_name == "Loyola-Chicago" & Season == 2017) %>%
    select(1:8, 24:45) %>%
     View()

 
loyola17_game_stats <- filter(reg_season_details_long, Team_name == "Loyola-Chicago" & Season == 2017)
mean(loyola17_game_stats$effective_fg_rate[1:29]) # this agrees with the value in reg_season_details_cumulative_stats on last game of season.

filter(reg_season_details_cumulative_stats, Team_name == "Loyola-Chicago" & Season == 2017) %>%
    inner_join(reg_season_details_cumulative_stats, by = "game_id") %>% 
    filter(Team_name.x != Team_name.y) %>%
    arrange(Season.x, DayNum.x) %>%
    View()

```

### Create head-to-head matchup data frame 
 
Each row currently represents the 1-day lag summary stats of each NCAA team prior to any given game in a season. Currently the `reg_season_details_cumulative_stats` dataset has 2 rows for each game_id, one representing team A's stats leading up to that game, another representing team B's. Since the goal of the problem is to predict if a given team will win a game against the other, the data frame needs to be reshaped to suit the problem.

Specifically, each row will still represent a game_id, but we want some columns for that game_id row representing team A's statistics, and and another set of columns representing their opponent's statistics, team B. The Target vector will represent the outcome of the game for Team A, Win or Loss. *Note that for a given game_id, we will only need one row to represent that game for both team's.*

``` {r}

head_to_head_stats <- reg_season_details_cumulative_stats %>%
    mutate(team_season_id = paste(Season, TeamID, sep = "_")) %>%
    # self-join to get opponents data on same row as team playing a game.
    inner_join(reg_season_details_cumulative_stats, by = "game_id") %>%
    # remove doops where Team A and Team A is it's opponent. 
    # b/c each game_id shows up twice in reg_season_details_cumulative_stats.
    filter(Team_name.x != Team_name.y) %>%
    rename_at(vars(ends_with(".x")), # for columns with .x (team outcome to predict)
              function(x) stringr::str_sub(x, start = 1L, end = -3L)) %>% # strip off the .x
    rename_at(vars(ends_with(".y")), # for columns with.y
              function(x) stringr::str_replace(x, "\\.y", "_OPP")) %>% # suffix w/ opponent.
    # Select variables
    select(game_id, team_season_id, tournament_type, Season, DayNum, TeamID, Team_name, 
           Team_conf, outcome, outcome_1_0,
           Loc, POM_rank, RPI_rank, SAG_rank, possessions, offense_efficiency, defense_efficiency,
           net_efficiency_ratio, score_diff, assist_to_fgm_ratio, effective_fg_rate,
           ORB_rate, DRB_rate, FT_rate, FTM_pct, offense_tov_per_100, 
           defense_effective_fg_rate, defense_FT_rate, defense_tov_per_100,
           opponent_ORB_rate, opponent_DRB_rate, PF_drawn_pg, PF_committed_pg, 
           average_tempo, season_wins, season_win_rate, ends_with("OPP")) %>%
    # remove unneeded variables about opponent.
    select(-Score_OPP, -Season_OPP, -DayNum_OPP, -outcome_OPP,
           -outcome_1_0_OPP,-Loc_OPP, -FGM_OPP, -FGA_OPP, -FGM3_OPP, -FGA3_OPP,
           -FTM_OPP, -FTA_OPP, -OR_OPP, -DR_OPP, -Ast_OPP, -TO_OPP, -Stl_OPP,
           -Blk_OPP, -PF_OPP) %>%
    arrange(Team_name, Season, DayNum) 

#head_to_head_stats %>%
#    filter(Team_name == "Loyola-Chicago" & Season == 2017) %>% View()
```

### Consider Matchup Differences (Comparative Advantage)

Since we have statistics about each team heading into the game, we can also develop predictor features that don't just consider team A and team B's respective performance stats, but also their head-to-head matchup differences on these performance stats. These performance differences might be even more powerful in predicting the outcome of a given game between two teams. An interesting insight I picked up from [here](http://dsal1951-portfolio-v1.businesscatalyst.com/portfolio/ncaa-bracket-selector.html) is that "*basketball is not transitive and the likelihood that Team A beats Team B is a function of each team's skill level **AND** how well the two teams "match up" against eachother.*" In other words, it's not good enough to just see which team ranks better than the other and pick that team. We need to model how these team's look compared to each other directly heading into a matchup on a battery of measures we think are driver's of game performance. 

As such, the next set of features below measure the comparative differences between team A and it's opponent heading into the game we're trying to predict. Note that some rows will return NA's at the beginning of a season because either or both team's playing the game may not yet have had a prior game that season yet to derive cumulative summary stats from. Anyways, earlier season games should probably be filtered from the modeling data due to small cumulative performance sample size in season. 

``` {r}
head_to_head_matchup_stats <- head_to_head_stats %>%
    mutate(conference_game_flag = Team_conf == Team_conf_OPP,
           possessions_DIFF = possessions - possessions_OPP, # basically the same as tempo_DIFF
           tempo_DIFF = average_tempo - average_tempo_OPP,
           offense_efficiency_DIFF = offense_efficiency - offense_efficiency_OPP,
           defense_efficiency_DIFF = defense_efficiency - defense_efficiency_OPP,
           net_efficiency_ratio_DIFF = net_efficiency_ratio - net_efficiency_ratio_OPP,
           score_margin_DIFF = score_diff - score_diff_OPP,
           assist_to_fgm_ratio_DIFF = assist_to_fgm_ratio - assist_to_fgm_ratio_OPP,
           effective_fg_rate_DIFF = effective_fg_rate - effective_fg_rate_OPP,
           ORB_rate_DIFF = ORB_rate - ORB_rate_OPP,
           DRB_rate_DIFF = DRB_rate - DRB_rate_OPP,
           FT_rate_DIFF = FT_rate - FT_rate_OPP,
           FTM_pct_DIFF = FTM_pct - FTM_pct_OPP,
           offense_tov_per_100_DIFF = offense_tov_per_100 - offense_tov_per_100_OPP,
           defense_effective_fg_rate_DIFF = defense_effective_fg_rate - defense_effective_fg_rate_OPP,
           defense_FT_rate_DIFF = defense_FT_rate - defense_FT_rate_OPP,
           defense_tov_per_100_DIFF = defense_tov_per_100 - defense_tov_per_100_OPP,
           # Difference in how each team allow's their opposition from getting ORB's.
           opponent_ORB_rate_DIFF = opponent_ORB_rate - opponent_ORB_rate_OPP,
           opponent_DRB_rate_DIFF = opponent_DRB_rate - opponent_DRB_rate_OPP,
           PF_drawn_pg_DIFF = PF_drawn_pg - PF_drawn_pg_OPP,
           PF_committed_pg_DIFF = PF_committed_pg - PF_committed_pg_OPP,
           season_wins_DIFF = season_wins - season_wins_OPP,
           season_win_rate_DIFF = season_win_rate - season_win_rate_OPP,
           POM_rank_DIFF = POM_rank_OPP - POM_rank, # how much better is the team ranked than opp. 
           RPI_rank_DIFF = RPI_rank_OPP - RPI_rank,
           SAG_rank_DIFF = SAG_rank_OPP - SAG_rank) %>%
    select(-team_season_id)
```

## Modeling Dataset

Things to do:

* create a holdout dataset of all 2014-2017 NCAA Tournament games (**stage1 test data**)
* identify the target vector, W or L. This will be the column of one of the team's in the head-to-head datasets.  
* Filter out features that aren't going to be considered as predictors. Only need the target vector and feature vectors.
* apply a **data sampling strategy**: make sure the data is balanced and records are independent. For instance, there should be about 50/50 proportion of W's and L's to predict, and no unique game should be included in the modeling dataset more than once. Additionally, very early season games won't be considered b/c the predictor features suffer from small sample size. I'll focus on games at the 1st quartile or later from a season, day `r `
* create a vector of the game_id_labels. Will need these to tie to our predictions later.

``` {r}

set.seed(321)
reg_season_sample <- head_to_head_matchup_stats %>%
    # drop games ineligible: 2014:2018 Season
    # games that are beginning of season have no 1-day lag summary stats. drop them.
    # also, only consider games starting after the quarter mark of the season.
    filter(complete.cases(.),
           Season %in% 2003:2013, 
           DayNum > quantile(RegularSeasonDetailedResults_Prelim2018$DayNum, .25),
           tournament_type == "regular season") %>%
    select(-Team_name, -outcome_1_0, -Season, -DayNum, -TeamID, -possessions, -possessions_OPP, -TeamID_OPP, -Team_name_OPP, -Loc, -tournament_type, -tournament_type_OP) %>%
    #select(game_id, outcome, Team_conf, conference_game_flag, ends_with("DIFF")) %>%
    # sample half of the games
    sample_frac(0.25) %>%
    # only keep one unique game_id row for modeling.
    group_by(game_id) %>%
    slice(1) %>%
    ungroup() %>%
    select(game_id, outcome, everything())

NCAA_tourney_2003_2013 <- head_to_head_matchup_stats %>%
    # include all NCAA tourney games from 2003 - 2013.
    filter(complete.cases(.),
           Season %in% 2003:2013, 
           tournament_type == "NCAA Tournament") %>%
    select(-Team_name, -outcome_1_0, -Season, -DayNum, -TeamID, -possessions, -possessions_OPP, -TeamID_OPP, -Team_name_OPP, -Loc, -tournament_type, -tournament_type_OPP) %>%
    # only keep one unique game_id row for modeling.
    group_by(game_id) %>%
    slice(1) %>%
    ungroup() %>%
    select(game_id, outcome, everything())


modeling_dataset <- bind_rows(reg_season_sample, NCAA_tourney_2003_2013) %>%
    mutate(outcome = factor(outcome, levels = c("L", "W")))
# reorder the rows randomly.
set.seed(321)
modeling_dataset <- modeling_dataset[sample(nrow(modeling_dataset)),]
modeling_game_id <- modeling_dataset$game_id

# contrasts(modeling_dataset$outcome)
```

## Random Forest (Ranger)

Try random forest model with `caret` and `ranger`.

```{r eval = FALSE, include = FALSE}
library(caret)
library(ranger)

training_setup <- trainControl(method = "cv",
                               number = 5,
                               savePredictions = TRUE,
                               summaryFunction = twoClassSummary, # needed for ROC metric
                               classProbs = TRUE) 

# define a grid of parameter options to try in ranger
rf_grid <- expand.grid(mtry = c(1, 5, 10, 15, 25),
                      splitrule = c("gini"),
                      min.node.size = c(1, 5))

set.seed(321)
rf_fit <- train(x = modeling_dataset[, -1],
                 y = modeling_dataset$outcome,
                 method = 'ranger',
                 trControl = training_setup,
                 metric = "ROC",
                 tuneGrid = rf_grid)

rf_fit
names(rf_fit) # what objects are stored in the variable importance
plot(varImp(rf_fit))
```

## Random Forest 

Try random forest model with `caret` and `randomforest`. This model was trained using over 70 predictors. 

```{r}
library(caret)
library(randomForest)

training_setup <- trainControl(method = "cv",
                               number = 5,
                               savePredictions = TRUE,
                               summaryFunction = twoClassSummary, # needed for ROC metric
                               classProbs = TRUE) 

# define a grid of parameter options to try in ranger
rf_grid <- expand.grid(mtry = c(1, 5, 10, 20, 30))

set.seed(321)
rf_fit <- train(x = modeling_dataset[, -c(1:2)],
                 y = modeling_dataset$outcome,
                 method = 'rf',
                 trControl = training_setup,
                 metric = "ROC",
                 tuneGrid = rf_grid)

rf_fit
names(rf_fit) # what objects are stored in the variable importance
varImp(rf_fit)
varImpPlot(rf_fit$finalModel)
plot(rf_fit)

rf_fit_2003_2013 <- rf_fit
# model saved on 3/12/18 at 8:17pm
#s3save(rf_fit_2003_2013, bucket = "ncaabasketball", object = "rf_fit_2003_2013.Rdata")

```

## Random Forest Subset1

Try random forest model with `caret` and `randomforest`. This model was trained on a subset of predictors that only measure matchup differences heading into the game. Nodesize was changed from default of 1 to 5. No effect on model performance, but improves run time.

```{r eval = FALSE, include = FALSE}
library(caret)
library(randomForest)

training_setup <- trainControl(method = "cv",
                               number = 5,
                               savePredictions = TRUE,
                               summaryFunction = twoClassSummary, # needed for ROC metric
                               classProbs = TRUE) 

# define a grid of parameter options to try in ranger
rf_grid <- expand.grid(mtry = c(1, 3, 5, 10, 20))

set.seed(321)
rf_fit_subset1_2003_2013 <- train(x = modeling_dataset[, c(51:78)],
                                  y = modeling_dataset$outcome,
                                  method = 'rf',
                                  trControl = training_setup,
                                  metric = "ROC",
                                  tuneGrid = rf_grid,
                                  nodesize = 5)

rf_fit_subset1_2003_2013
varImpPlot(rf_fit_subset1_2003_2013$finalModel)
plot(rf_fit_subset1_2003_2013)

s3save(rf_fit_subset1_2003_2013, bucket = "ncaabasketball", object = "rf_fit_2003_2013.Rdata")

```



## Test the model on the 2013-2017 NCAA Tourney Games

``` {r}
ncaa_2014_teams <- head_to_head_stats %>%
    filter(Season == 2014  & tournament_type == "NCAA Tournament") %>%
    distinct() %>%
    select(TeamID) %>%
    unique(.)
ncaa_2014_teams <- ncaa_2014_teams$TeamID
    
ncaa_2015_teams <- head_to_head_stats %>%
    filter(Season == 2015  & tournament_type == "NCAA Tournament") %>%
    distinct() %>%
    select(TeamID) %>%
    unique(.)
ncaa_2015_teams <- ncaa_2015_teams$TeamID

ncaa_2016_teams <- head_to_head_stats %>%
    filter(Season == 2016  & tournament_type == "NCAA Tournament") %>%
    distinct() %>%
    select(TeamID) %>%
    unique(.)
ncaa_2016_teams <- ncaa_2016_teams$TeamID

ncaa_2017_teams <- head_to_head_stats %>%
    filter(Season == 2017  & tournament_type == "NCAA Tournament") %>%
    distinct() %>%
    select(TeamID) %>%
    unique(.)
ncaa_2017_teams <- ncaa_2017_teams$TeamID



ncaa_2014_test_data <- head_to_head_stats %>%
    filter(Season == 2014,
        tournament_type == "regular season",
        TeamID %in% ncaa_2014_teams) %>%
    group_by(TeamID, Season) %>%
    arrange(TeamID, Season, desc(DayNum)) %>%
    slice(1) %>%
    ungroup() %>%
    select(6:7,11:37)

expand.grid(ncaa_2014_test_data, ncaa_2014_test_data
```
